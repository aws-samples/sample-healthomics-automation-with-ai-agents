{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß¨ Multi-Agent Genomics Pipeline: Graph Patterns and Edge Conditions\n",
    "\n",
    "This notebook demonstrates advanced Strands Agents concepts by building a complete **Multi-Agent Genomics Pipeline** using the Graph pattern with conditional execution and quality gates. The goal of the agent is to take a sample ID for a cancer sample (tumor/ normal pair) as input and process that through multiple steps to identify the significance of any genomic mutations in that sample.\n",
    "\n",
    "## üéØ What You'll Learn\n",
    "\n",
    "1. **Multi-Agent Patterns** - Graph, Swarm, and Workflow architectures\n",
    "2. **Graph Construction** - Building deterministic agent workflows\n",
    "3. **Edge Conditions** - Conditional execution based on agent results\n",
    "4. **Quality Gates** - Data quality assessment and flow control\n",
    "5. **Agent Orchestration** - Coordinating specialized agents\n",
    "6. **Production Deployment** - AgentCore deployment for multi-agent systems\n",
    "\n",
    "## üèóÔ∏è What We'll Build\n",
    "\n",
    "A complete **Genomics Analysis Pipeline** with four specialized agents:\n",
    "\n",
    "1. **üîç Data Discovery Agent** - Find genomics data files\n",
    "2. **üî¨ Quality Control Agent** - Assess data quality (with quality gate)\n",
    "3. **‚öôÔ∏è Workflow Orchestrator Agent** - Run variant calling workflows\n",
    "4. **üìä Interpretation Agent** - Generate clinical reports\n",
    "\n",
    "## üï∏Ô∏è Multi-Agent Graph Architecture\n",
    "\n",
    "The agents are connected in a **directed graph** with **conditional edges** that create quality gates:\n",
    "\n",
    "![image.png](./image.png)\n",
    "\n",
    "### üîó **Graph Components:**\n",
    "\n",
    "#### **Nodes (Agents):**\n",
    "- **Entry Point**: üîç Data Discovery Agent\n",
    "- **Always Execute**: üîç Data Discovery ‚Üí üî¨ Quality Control\n",
    "- **Conditional Execute**: ‚öôÔ∏è Workflow Orchestrator (quality gate)\n",
    "- **Conditional Execute**: üìä Interpretation Agent (completion gate)\n",
    "\n",
    "#### **Edges (Connections):**\n",
    "1. **üîç ‚Üí üî¨** (Unconditional): Always proceed to quality control\n",
    "2. **üî¨ ‚Üí ‚öôÔ∏è** (Conditional): `quality_passed_condition()`\n",
    "3. **‚öôÔ∏è ‚Üí üìä** (Conditional): `workflow_completed_condition()`\n",
    "\n",
    "#### **Edge Conditions (Quality Gates):**\n",
    "- **Quality Gate**: Analyzes QC results for phrases like:\n",
    "  - ‚úÖ \"Data quality status: SUFFICIENT for variant calling\"\n",
    "  - ‚ùå \"Data quality status: INSUFFICIENT for variant calling\"\n",
    "- **Completion Gate**: Checks workflow results for:\n",
    "  - ‚úÖ \"Workflow execution completed successfully\"\n",
    "  - ‚ùå \"Workflow execution failed\"\n",
    "\n",
    "### üéØ **Execution Flow:**\n",
    "1. **Always**: Data Discovery finds genomics files\n",
    "2. **Always**: Quality Control assesses data quality\n",
    "3. **If quality passes**: Workflow Orchestrator runs variant calling\n",
    "4. **If workflow succeeds**: Interpretation Agent generates clinical reports\n",
    "5. **If quality fails**: Pipeline stops after QC with quality assessment\n",
    "6. **If workflow fails**: Pipeline stops after orchestrator with failure diagnosis\n",
    "\n",
    "This architecture ensures **data-driven decision making** and **resource efficiency** by only running expensive computations when data quality is sufficient!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Part 1: Multi-Agent Patterns Overview\n",
    "\n",
    "### Why Use Multiple Agents\n",
    "\n",
    "1. Artificial General Intelligence (AGI) isn't here yet meaning one agent probably can't do everything\n",
    "2. Individual agents can be specialized with crisp system prompts\n",
    "3. Agents with fewer tools use fewer tokens to 'understand' those tools\n",
    "4. Agents with simpler tasks can use simpler (and more cost effective) models or more specialized models\n",
    "\n",
    "### Strands Multi-Agent Patterns\n",
    "\n",
    "Strands Agents supports three primary multi-agent patterns:\n",
    "\n",
    "#### 1. **Graph Pattern** (What we'll build)\n",
    "- **Deterministic flow** with defined dependencies\n",
    "- **Conditional execution** based on agent results\n",
    "- **Quality gates** and validation checkpoints\n",
    "- **Best for**: Structured workflows with clear dependencies\n",
    "\n",
    "#### 2. **Swarm Pattern**\n",
    "- **Collaborative agents** working together\n",
    "- **Dynamic task distribution**\n",
    "- **Shared context and memory**\n",
    "- **Best for**: Complex problem-solving requiring multiple perspectives\n",
    "\n",
    "#### 3. **Workflow Pattern**\n",
    "- **Sequential execution** with handoffs\n",
    "- **State management** between agents\n",
    "- **Error recovery** and retry logic\n",
    "- **Best for**: Linear processes with clear stages\n",
    "\n",
    "### Why Graph Pattern for Genomics?\n",
    "\n",
    "Genomics analysis requires:\n",
    "- **Quality validation** before expensive computations\n",
    "- **Conditional execution** based on data quality\n",
    "- **Deterministic flow** for reproducible results\n",
    "- **Specialized agents** for different analysis stages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Step 1: Environment Setup and Dependencies\n",
    "\n",
    "Let's set up our environment for multi-agent development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required dependencies for multi-agent systems\n",
    "!pip install strands-agents boto3 pandas --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß± Step 2: The Individual Agents\n",
    "\n",
    "The genomics multi agent is composed of four specialized agents. These have been created as python files and all follow patterns introduced in [notebook 01](01-strands-agents-introduction.ipynb). Feel free to review the individual agent definitions as you read through the descriptions here.\n",
    "\n",
    "### üïµÔ∏è‚Äç‚ôÄÔ∏è Data Discovery Agent\n",
    "\n",
    "The data discovery agent is responsible for identifying genomics files in S3 that meet the requirements of the user. It uses tools provided by an MCP server to achieve this goal.\n",
    "\n",
    "[data_discovery_agent.py](data_discovery_agent.py)\n",
    "\n",
    "### üî¨ Quality Control Agent\n",
    "\n",
    "Next up is the quality control agent which is responsible for assessing the quality of the genomics data files. This agent will be executed after the data discovery agent and will provide recommendations on whether to proceed with variant calling or not. It has built in `@tool` functions that let it locate, download, unpack and review FASTQ quality reports. It summarizes the quality of the data and makes recommendations to proceed or stop.\n",
    "\n",
    "[qc_agent.py](qc_agent.py)\n",
    "\n",
    "### üë∑ Workflow Orchestrator Agent\n",
    "\n",
    "The workflow orchestrator is essentially the same as what we built in [notebook 01](01-strands-agents-introduction.ipynb). It runs the\n",
    "workflow required to analyze the samples.\n",
    "\n",
    "[workflow_orchestrator_agent.py](workflow_orchestrator_agent.py)\n",
    "\n",
    "### üßë‚Äçüíª Interpretation and Reporting Agent\n",
    "\n",
    "The interpretation and reporting agent features a number of `@tool`s that give the agent the ability to load\n",
    "MAF files as well as various CIViC data files. These tools are used to load the MAF file generated by the tumor/ normal variant caller and perform the analysis. Using the data the tool generates a report with example clinical recommendations.\n",
    "\n",
    "[interpretation_and_reporting_agent.py](interpretation_and_reporting_agent.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîó Step 3: Understanding Edge Conditions\n",
    "\n",
    "Edges are used to connect the nodes (agents) in the graph. Edge conditions determine when edges should be traversed and when agents should execute based on previous or results of other conditions. An edge condition is any function that uses the agent state to return a `bool`.\n",
    "\n",
    "Here, we make an edge condition function that will analyze the output of the QC agent to determine if it is sufficient to continue with variant calling. This implementation is a simplistic sentiment analysis that is suitable for simple cases (and this demonstration). A more sophisticated and robust edge condition could use vector embeddings and vector distance to achieve the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile edge_functions.py\n",
    "\n",
    "import logging\n",
    "from strands.multiagent.base import NodeResult, Status\n",
    "from typing import Any, Optional\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def quality_passed_condition(state: Any) -> bool:\n",
    "    \"\"\"Check if QC results indicate acceptable data quality for variant calling.\n",
    "    \n",
    "    This condition function analyzes the QC agent's results to determine if the\n",
    "    sequencing data quality is sufficient to proceed with variant calling.\n",
    "    \n",
    "    Args:\n",
    "        state: GraphState containing results from executed nodes\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if quality is acceptable, False otherwise\n",
    "    \"\"\"\n",
    "    # Get QC results from the graph state\n",
    "    qc_results: Optional[NodeResult] = state.results.get('qc_agent')\n",
    "    if not qc_results:\n",
    "        logger.warning(\"No QC results available for quality assessment\")\n",
    "        return False\n",
    "    \n",
    "    # Analyze QC results to determine if quality is acceptable\n",
    "    qc_result_text: str = str(qc_results.result).lower()\n",
    "    \n",
    "    # Look for definitive quality assessment phrases\n",
    "    definitive_good_phrases = [\n",
    "        'sufficient for somatic variant calling',\n",
    "        'sufficient for variant calling', \n",
    "        'data quality status: sufficient',\n",
    "        'suitable for somatic variant calling',\n",
    "        'proceed with confidence'\n",
    "    ]\n",
    "    \n",
    "    definitive_bad_phrases = [\n",
    "        'insufficient for variant calling',\n",
    "        'data quality status: insufficient',\n",
    "        'poor data quality',\n",
    "        'not suitable for variant calling',\n",
    "        'quality too low',\n",
    "        'do not proceed'\n",
    "    ]\n",
    "    \n",
    "    # Check for definitive assessment phrases\n",
    "    for phrase in definitive_good_phrases:\n",
    "        if phrase in qc_result_text:\n",
    "            logger.info(\"Quality gate: PASSED - Found definitive positive quality assessment\")\n",
    "            return True\n",
    "            \n",
    "    for phrase in definitive_bad_phrases:\n",
    "        if phrase in qc_result_text:\n",
    "            logger.info(\"Quality gate: FAILED - Found definitive negative quality assessment\")\n",
    "            return False\n",
    "    \n",
    "    # Fallback to indicator counting if no definitive phrases found\n",
    "    quality_indicators = {\n",
    "        'good': ['‚úÖ pass', 'good quality', 'acceptable', 'high quality', 'suitable', 'meets', 'adequate', 'excellent'],\n",
    "        'bad': ['poor quality', 'failed', 'low quality', 'unacceptable', 'contamination detected', 'below threshold', 'insufficient']\n",
    "    }\n",
    "    \n",
    "    good_score = sum(1 for indicator in quality_indicators['good'] if indicator in qc_result_text)\n",
    "    bad_score = sum(1 for indicator in quality_indicators['bad'] if indicator in qc_result_text)\n",
    "    \n",
    "    # Quality passes if we have more good indicators than bad ones\n",
    "    quality_passed = good_score > bad_score\n",
    "    \n",
    "    if quality_passed:\n",
    "        logger.info(f\"Quality gate: PASSED - Data suitable for variant calling (good: {good_score}, bad: {bad_score})\")\n",
    "    else:\n",
    "        logger.info(f\"Quality gate: FAILED - Data quality insufficient (good: {good_score}, bad: {bad_score})\")\n",
    "    \n",
    "    return quality_passed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the variant calling workflow fails, then it doesn't really make sense to proceed with the analysis so we will construct another edge condition that will only proceed to the analysis agent if the workflow is complete and successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a edge_functions.py\n",
    "\n",
    "def workflow_completed_condition(state: Any) -> bool:\n",
    "    \"\"\"Check if workflow orchestrator completed successfully.\n",
    "    \n",
    "    Args:\n",
    "        state: GraphState containing results from executed nodes\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if workflow completed successfully, False otherwise\n",
    "    \"\"\"\n",
    "    # Get workflow results from the graph state\n",
    "    workflow_results: Optional[NodeResult] = state.results.get('workflow_orchestrator')\n",
    "    if not workflow_results:\n",
    "        logger.warning(\"No workflow orchestrator results available\")\n",
    "        return False\n",
    "    \n",
    "    # Check if workflow completed successfully\n",
    "    workflow_result_text: str = str(workflow_results.result).lower()\n",
    "    \n",
    "    # Look for success indicators\n",
    "    success_indicators = [\n",
    "        'workflow execution completed successfully',\n",
    "        'workflow completed successfully',\n",
    "        'run completed',\n",
    "        'succeeded',\n",
    "        'status: completed',\n",
    "        '‚úÖ completed',\n",
    "        'completed successfully',\n",
    "        'vcf file',\n",
    "        'filtered.vcf',\n",
    "        'final output',\n",
    "        'workflow finished'\n",
    "    ]\n",
    "    \n",
    "    failure_indicators = [\n",
    "        'workflow execution failed',\n",
    "        'workflow failed',\n",
    "        'run failed',\n",
    "        'error',\n",
    "        'failed to complete',\n",
    "        'timeout',\n",
    "        'cancelled'\n",
    "    ]\n",
    "    \n",
    "    # Check for definitive success/failure indicators\n",
    "    for indicator in success_indicators:\n",
    "        if indicator in workflow_result_text:\n",
    "            logger.info(f\"Workflow condition: PASSED - Found success indicator: {indicator}\")\n",
    "            return True\n",
    "            \n",
    "    for indicator in failure_indicators:\n",
    "        if indicator in workflow_result_text:\n",
    "            logger.info(\"Workflow condition: FAILED - Workflow did not complete successfully\")\n",
    "            return False\n",
    "    \n",
    "    # If no clear indicators, check status\n",
    "    if workflow_results.status == Status.COMPLETED:\n",
    "        logger.info(\"Workflow condition: PASSED - Node status indicates completion\")\n",
    "        return True\n",
    "    else:\n",
    "        logger.info(\"Workflow condition: FAILED - Node status indicates failure\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Step 4: Build the Graph Agent\n",
    "\n",
    "With the individual agents and edge conditions defined, it is time to build a function that will assemble the Graph agent. This is achieved by adding the agents as nodes and connecting the nodes with edges, some of which are conditional. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile graph_agent.py\n",
    "\n",
    "import logging\n",
    "import boto3\n",
    "\n",
    "from mcp_clients import setup_mcp_clients\n",
    "from data_discovery_agent import create_data_discovery_agent\n",
    "from qc_agent import create_qc_agent\n",
    "from workflow_orchestrator_agent import create_healthomics_agent\n",
    "from interpretation_and_reporting_agent import create_cancer_analysis_agent\n",
    "from edge_functions import quality_passed_condition, workflow_completed_condition\n",
    "\n",
    "from strands import Agent\n",
    "from strands.multiagent import GraphBuilder\n",
    "from strands.multiagent.graph import Graph\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def build_genomics_graph(healthomics_client, aws_api_client) -> Graph:\n",
    "    \"\"\"Build the complete genomics multi-agent graph\"\"\"\n",
    "\n",
    "    # Get tools from MCP clients\n",
    "    healthomics_tools = healthomics_client.list_tools_sync()\n",
    "    aws_tools = aws_api_client.list_tools_sync()\n",
    "\n",
    "    # Create agents with appropriate tools\n",
    "    data_discovery_agent = create_data_discovery_agent(healthomics_tools)\n",
    "    data_discovery_agent.name = \"data_discovery\"\n",
    "    data_discovery_agent.description = \"Discovers genomics data files for analysis\"\n",
    "    data_discovery_agent.system_prompt = \"\"\"\n",
    "    You are responsible for identifying FASTQ files that the user is looking for.\n",
    "    1. Find files in S3 that seem like the best match\n",
    "    2. Report the S3 URIs for use by the next agent\n",
    "\n",
    "    Provide terse and very focussed responses.\n",
    "    Perform only these tasks, when you have completed these tasks handoff to the next agent.\n",
    "    \"\"\"\n",
    "\n",
    "    qc_agent = create_qc_agent(aws_tools)\n",
    "    qc_agent.name = \"qc_agent\"\n",
    "    qc_agent.description = \"Analyzes sequencing data quality and provides recommendations\"\n",
    "    qc_agent.system_prompt = \"\"\"\n",
    "    You are responsible for analyzing sequencing data quality and reporting on it's quality. You will be given information including a URI\n",
    "    for one or more files. \n",
    "    1. Find the FASTQC reports for these files. These QC reports might be in a sibling directory relative to\n",
    "    the location of the FASTQ files. \n",
    "    2. Determine if the quality is acceptable for somatic variant calling which will be performed by \n",
    "    another agent along with reasons why or why not.\n",
    "    3. Ensure you include the full URIs of any files you are reporting on for use by the next agent\n",
    "\n",
    "    Provide terse and very focussed responses.\n",
    "    Perform only these tasks, when you have completed these tasks handoff to the next agent.\n",
    "    \"\"\"\n",
    "\n",
    "    workflow_orchestrator = create_healthomics_agent(healthomics_tools + aws_tools)\n",
    "    workflow_orchestrator.name = \"workflow_orchestrator\"\n",
    "    workflow_orchestrator.description = \"Orchestrates genomics workflows when data quality is sufficient\"\n",
    "    workflow_orchestrator.system_prompt = \"\"\"\n",
    "    You are responsible for orchestrating genomics workflows. You will be given URIs for FASTQ pairs from tumor/ normal\n",
    "    samples. Your job is to:\n",
    "\n",
    "    1. Find the aligned BAM files associated with these reads\n",
    "    2. Run the most recent version of the genomics-ai-workshop-mutect2 workflow on the data \n",
    "        - When running the workflow you are responsible for finding the IAM OmicsServiceRole\n",
    "        - The workflow outputs bucket is in my account and begins with s3://genomics-ai-workshop-results\n",
    "        - Run the workflow in 'cooking show' mode and set vcf2maf_output to s3://aws-genomics-static-us-east-1/omics-data/tumor-normal/maf/test_civic.maf\n",
    "    3. After starting the workflow run, use your built-in wait_for_workflow tool with the run ID to monitor the run status until completion.\n",
    "    4. If the run fails, then diagnose the problem and report on potential solutions.\n",
    "    5. If the run succeeds report the S3 URIs of all output files generated by the workflow. These will be used by the next agent.\n",
    "\n",
    "    Provide terse and very focussed responses.\n",
    "    Perform only these tasks, when you have completed these tasks handoff to the next agent.\n",
    "    \"\"\"\n",
    "\n",
    "    interpretation_agent = create_cancer_analysis_agent(aws_tools)\n",
    "    interpretation_agent.name = \"interpretation_agent\"\n",
    "    interpretation_agent.description = \"Interprets cancer variants and generates clinical reports\"\n",
    "    interpretation_agent.system_prompt = \"\"\"\n",
    "    You are responsible for interpreting cancer variants and generating clinical reports. You will be given the S3 URI of a MAF file\n",
    "    containing somatic variants from the workflow orchestrator. Your job is to:\n",
    "\n",
    "    1. Load the MAF file from the provided S3 URI\n",
    "    2. Load CIViC annotation files for clinical evidence matching\n",
    "    3. Match variants with CIViC database to find clinical evidence and therapeutic recommendations\n",
    "    4. Generate a comprehensive clinical report with evidence-based therapeutic recommendations\n",
    "    5. Upload the clinical report to S3 for sharing and archival (use generate_and_upload_clinical_report)\n",
    "    6. Provide appropriate guidance for both matched variants (with clinical evidence) and unmatched variants (rare/novel)\n",
    "    7. Write the final report to the bucket my account that begins with s3://genomics-ai-workshop-results\n",
    "\n",
    "    Always provide clinically appropriate, evidence-based recommendations while being clear about the limitations of available data.\n",
    "    When uploading reports to S3, use a meaningful filename and path structure (e.g., s3://bucket/reports/YYYY-MM-DD/sample_clinical_report.md).\n",
    "    \"\"\"\n",
    "\n",
    "    logger.info(\"ü§ñ All agents created with proper configurations\")\n",
    "\n",
    "    # Build the multi-agent graph\n",
    "    builder = GraphBuilder()\n",
    "\n",
    "    # Add nodes (four specialized agents) - all should be agent instances\n",
    "    builder.add_node(data_discovery_agent, \"data_discovery\")\n",
    "    builder.add_node(qc_agent, \"qc_agent\")\n",
    "    builder.add_node(workflow_orchestrator, \"workflow_orchestrator\")\n",
    "    builder.add_node(interpretation_agent, \"interpretation_agent\")\n",
    "\n",
    "    logger.info(\"üìä Graph nodes added\")\n",
    "\n",
    "    # Add edges with conditional logic\n",
    "    builder.add_edge(\"data_discovery\", \"qc_agent\")\n",
    "    builder.add_edge(\"qc_agent\", \"workflow_orchestrator\", condition=quality_passed_condition)\n",
    "    builder.add_edge(\"workflow_orchestrator\", \"interpretation_agent\", condition=workflow_completed_condition)\n",
    "\n",
    "    # Set entry point\n",
    "    builder.set_entry_point(\"data_discovery\")\n",
    "\n",
    "    # Configure execution limits\n",
    "    builder.set_execution_timeout(3600)   # 1 hour\n",
    "    builder.set_node_timeout(1800)        # 30 minutes per node\n",
    "\n",
    "    # Build the graph\n",
    "    graph = builder.build()\n",
    "\n",
    "    logger.info(\"‚úÖ Genomics multi-agent graph built successfully!\")\n",
    "    return graph\n",
    "\n",
    "# Global variables for clients and graph\n",
    "_healthomics_client = None\n",
    "_aws_api_client = None\n",
    "_genomics_graph = None\n",
    "_clients_initialized = False\n",
    "\n",
    "def get_or_create_graph():\n",
    "    \"\"\"Get the genomics graph, keeping MCP clients active\"\"\"\n",
    "    global _healthomics_client, _aws_api_client, _genomics_graph, _clients_initialized\n",
    "\n",
    "    if _genomics_graph is None:\n",
    "        # Initialize clients once and keep them active\n",
    "        _healthomics_client, _aws_api_client = setup_mcp_clients()\n",
    "\n",
    "        # Enter the context managers but don't exit them\n",
    "        _healthomics_client.__enter__()\n",
    "        _aws_api_client.__enter__()\n",
    "        _clients_initialized = True\n",
    "\n",
    "        # Build graph with active clients\n",
    "        _genomics_graph = build_genomics_graph(_healthomics_client, _aws_api_client)\n",
    "\n",
    "    return _genomics_graph\n",
    "\n",
    "\n",
    "def run_graph_locally(prompt: str):\n",
    "    \"\"\"Run the graph locally with a prompt (for testing)\"\"\"\n",
    "    import asyncio\n",
    "    \n",
    "    async def _run():\n",
    "        graph = get_or_create_graph()\n",
    "        print(f\"\\nüöÄ Running graph with prompt: {prompt}\\n\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Execute the graph\n",
    "        result = await graph.invoke_async(prompt)\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"\\nStatus: {result.status}\")\n",
    "        print(f\"Completed Nodes: {result.completed_nodes}/{result.total_nodes}\")\n",
    "        print(f\"Execution Time: {result.execution_time}ms\")\n",
    "        \n",
    "        print(\"\\n\" + \"-\"*80)\n",
    "        for node_id, node_result in result.results.items():\n",
    "            print(f\"\\nüîπ {node_id}: {node_result.status}\")\n",
    "            if node_result.result:\n",
    "                result_text = str(node_result.result)\n",
    "                if len(result_text) > 300:\n",
    "                    print(f\"   {result_text[:300]}...\")\n",
    "                else:\n",
    "                    print(f\"   {result_text}\")\n",
    "        \n",
    "        print(\"=\"*80)\n",
    "        print(\"\\n‚úÖ Graph execution completed\\n\")\n",
    "    \n",
    "    asyncio.run(_run())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage when running directly\n",
    "    import sys\n",
    "    if len(sys.argv) > 1:\n",
    "        prompt = \" \".join(sys.argv[1:])\n",
    "        run_graph_locally(prompt)\n",
    "    else:\n",
    "        print(\"Usage: python graph_agent.py \\\"Your prompt here\\\"\")\n",
    "        print(\"\\nExample:\")\n",
    "        print('  python graph_agent.py \"Analyze genomics data for sample P001\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Step 5: Running the Graph Agent\n",
    "\n",
    "Now that we've built the complete multi-agent graph, let's test it! We've created a standalone script that allows you to run the graph agent from the command line.\n",
    "\n",
    "### Running from Command Line\n",
    "\n",
    "Use the `run_graph_agent.py` script to interact with the graph agent:\n",
    "\n",
    "```bash\n",
    "python run_graph_agent.py \"Find and analyze genomics data for sample P001\"\n",
    "```\n",
    "\n",
    "The script will:\n",
    "1. Initialize the MCP clients\n",
    "2. Build the multi-agent graph\n",
    "3. Stream the response as each agent executes\n",
    "4. Display results from each node in the graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_graph_agent.py \"Find and analyze genomics data for sample P001\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Output\n",
    "\n",
    "As the graph executes, you'll see a lot of output:\n",
    "- **Node transitions**: Which agent is currently executing\n",
    "- **Tool use**: Which tools are being used by each agent\n",
    "- **MCP logs**: Detailed logs from the MCP clients\n",
    "- **Agent outputs**: Results from each specialized agent\n",
    "- **Workflow monitoring**: Monitoring of the workflow orchestration agent when the workflow is running\n",
    "- **Quality gates**: Whether conditions passed or failed\n",
    "- **Final results**: Complete analysis or early termination based on quality\n",
    "\n",
    "Because none of the agents have explicit instructions on exactly how to perform their actions you will also see them reasoning\n",
    "about their task, making mistakes and trying different approaches. For example, the workflow agent needs to find BAM files associated\n",
    "with a sample as well as locate a reference genome and identify an IAM Role suitable for the workflow. It may make one or more guesses\n",
    "about these but when it gets feedback on it's mistakes it will have to go looking for them to succeed.\n",
    "\n",
    "The graph will automatically:\n",
    "- Stop after QC if data quality is insufficient\n",
    "- Stop after workflow orchestration if the workflow fails\n",
    "- Complete all agents if quality passes and workflow succeeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Summary: Multi-Agent Genomics Pipeline\n",
    "\n",
    "Congratulations! You've successfully built a sophisticated **Multi-Agent Genomics Pipeline** using advanced Strands Agents patterns. Here's what we accomplished:\n",
    "\n",
    "### üèóÔ∏è **Multi-Agent Architecture**\n",
    "1. **Graph Pattern** - Deterministic workflow with conditional execution\n",
    "2. **Four Specialized Agents** - Each with specific genomics expertise\n",
    "3. **Quality Gates** - Data-driven decision making with edge conditions\n",
    "4. **MCP Integration** - Multiple tool servers for comprehensive capabilities\n",
    "\n",
    "### üîó **Key Multi-Agent Concepts**\n",
    "- **GraphBuilder**: Constructing deterministic agent workflows\n",
    "- **Edge Conditions**: Conditional execution based on agent results\n",
    "- **Quality Gates**: Automated quality assessment and flow control\n",
    "- **Agent Orchestration**: Coordinating specialized agents for complex tasks\n",
    "\n",
    "### üìö **What You've Learned**\n",
    "1. **Multi-Agent Patterns** - When and how to use Graph, Swarm, and Workflow patterns\n",
    "2. **Conditional Execution** - Building intelligent decision points in agent workflows\n",
    "3. **Quality Gates** - Implementing data-driven flow control\n",
    "4. **Agent Specialization** - Creating focused agents for specific tasks\n",
    "\n",
    "You now have the skills to build sophisticated multi-agent systems that can handle complex, real-world genomics workflows with intelligent decision making and robust error handling! üß¨ü§ñ‚ú®"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
